# -*- coding: utf-8 -*-
"""data_scraping_demo.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CyueNmqs4egcRX_ipzTnJVGFJmHnlDuj

# **Data Scraping from API**
"""

import requests
import time

response_query = requests.get("https://api.myanimelist.net/v2/anime?q=one&limit=4",
                              headers={'X-MAL-CLIENT-ID': '6114d00ca681b7701d1e15fe11a4987e'})
print("status_code:", response_query.status_code)

response_query.json()

anime = response_query.json()['data'][0]['node']
anime_id = anime['id']
anime

response_details = requests.get(f'https://api.myanimelist.net/v2/anime/{anime_id}?fields=id,title,main_picture,alternative_titles,start_date,end_date,synopsis,mean,rank,popularity,num_list_users,num_scoring_users,nsfw,created_at,updated_at,media_type,status,genres,my_list_status,num_episodes,start_season,broadcast,source,average_episode_duration,rating,pictures,background,related_anime,related_manga,recommendations,studios,statistics',
                        headers={'X-MAL-CLIENT-ID': '6114d00ca681b7701d1e15fe11a4987e'})
print("Response:", response_details.status_code)

print("Avaiable Features from API:")
print("-----")
for feature in response_details.json().keys():
    print(feature)

"""### **Analyze the above Features**

We observe that there are several features that we dont need to use in our dataset.
Therefore, we try to keep the following features:


---
1. id
2. title
3. start_date
4. end_date
5. synopsis
6. mean
7. rank
8. popularity
9. num_list_users
10. num_scoring_users
11. nsfw
12. created_at
13. updated_at
14. media_type
15. status
16. genres
17. num_episodes
18. start_season
19. broadcast
20. source
21. average_episode_duration
22. rating
23. background
24. studios
25. statistics

## **How to Get Data Demo for above Features**

Suppose we want to get the animes from 2000-2021 (four seasons for each year)
"""

response = requests.get('https://api.myanimelist.net/v2/anime/season/2017/summer?limit=4',
                            headers={'X-MAL-CLIENT-ID': '6114d00ca681b7701d1e15fe11a4987e'})

response.json()['data']

'''
Season name	 Months
winter	   January, February, March
spring	   April, May, June
summer	   July, August, September
fall	    October, November, December
'''
seasons = [
    "winter",
    "spring",
    "summer",
    "fall"
]

anime_list = []
def get_anime(year, season, anime_list):
    # fetch 250 animes from a particular {season} of a particular {year}
    response = requests.get(f'https://api.myanimelist.net/v2/anime/season/{year}/{season}?limit=100',
                            headers={'X-MAL-CLIENT-ID': '6114d00ca681b7701d1e15fe11a4987e'})
    print(f'Status ({year}/{season})', response.status_code)
    for anime in response.json()['data']:
      anime_id = anime['node']['id']
      # query for anime details
      response_details = requests.get(f'https://api.myanimelist.net/v2/anime/{anime_id}?fields=id,title,start_date,end_date,synopsis,mean,rank,popularity,num_list_users,num_scoring_users,nsfw,created_at,updated_at,media_type,status,genres,my_list_status,num_episodes,start_season,broadcast,source,average_episode_duration,rating,background,studios,statistics',
                          headers={'X-MAL-CLIENT-ID': '6114d00ca681b7701d1e15fe11a4987e'})
      # add anime details to list
      anime_list.append(response_details.json())
    print(f'({year}/{season}) done!')
    print('---')
    return anime_list
anime_list = get_anime(2000, seasons[0], anime_list)
print(anime_list)

import pandas as pd

anime_df = pd.DataFrame(anime_list)
anime_df.head()

print(anime_df.shape)

"""## **The Process for Graping Data**

For this demo, we provide the specific year and season which are 2000 and winter into the function. And we first use the api to get the anime id inside this seaon. And then we use api again to gain the information for each anime id with the features we want.
"""